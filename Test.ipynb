{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scientist interview test\n",
    "\n",
    "## Part 1 - Data loading and basic statistics\n",
    "\n",
    "In the ```Data``` folder, you will find a file named ```diamonds.csv```. This file containts information on 53940 diamonds. Among the available information, you will find the price, color, weight, etc. You can look at the dataset's complete characteristics [here](https://www.kaggle.com/shivam2503/diamonds).\n",
    "\n",
    "1. Load the file in a pandas dataframe.\n",
    "2. Briefly describe the data along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to part 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Unsupervised learning\n",
    "\n",
    "You are tasked with finding structure among the given data. \n",
    "\n",
    "1. Using the loaded data of the previous point, use a non-supervised clustering algorithm to cluster the diamonds with similar properties.\n",
    "2. In a markdown cell, state and describe a metric to evaluate the quality of your clusters. \n",
    "3. Vary $k$ (the amount of clusters) between 1 and 10 and graph your metric as a function of $k$\n",
    "4. What $k$ is the most appropriate for the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to part 2 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Dimensionality reduction and regression\n",
    "\n",
    "You want to predict the price of the diamonds from their characteristics. You suspect that various columns of the dataset are redundant. That is to say, there are columns that dont add new information. \n",
    "\n",
    "1. Reduce the dimensionality of the data to avoid having redundant information. Make sure that your new representation space explains at least 90% of the data's variance.\n",
    "2. In a markdown cell, describe a metric that can be used to evaluate the quality of a regression\n",
    "3. Split the data in a train and test set\n",
    "4. In the new representation space, train a regression algorithm to predict the price of diamonds on the train set. Evaluate your algorithm with your metric on the test set. How well does the algorithm perform? Is it fit for production? Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to part 3 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - classification\n",
    "\n",
    "In the ```Data``` folder, you will find a file named ```emotions.csv``` that contains information on the electromagnetic waves emitted by the brains of 2 patients. There are a total of 2549 columns (including the target column) with 2132 entries. Your job is to predict the patient's emotional state (the label column) from the other columns. You can look at a complete description of the dataset [here](https://www.kaggle.com/birdy654/eeg-brainwave-dataset-feeling-emotions). \n",
    "\n",
    "Implement a pipeline with what you consider necessary to cary out this task. You are free to choose the tools and algorithms of your choice as long as you comply with the following:\n",
    "\n",
    "1. You must implement at least 2 classification algorithms\n",
    "2. You must graph the confusion matrix and the precision-recall curves for each algorithm \n",
    "\n",
    "Compare your classifier's results. Which algorithm is better? Is the best algorithm fit for production? Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to part 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Deployment\n",
    "\n",
    "Deploy your best classifier from part 4 as an endpoint that takes the body of an http POST request. The body of the request will be in the following JSON format:\n",
    "\n",
    "```\n",
    "{\"input\":[val1,val2,val3, ... ,val2548]}\n",
    "\n",
    "```\n",
    "The order of the values in the list correspond to the input columns of the `emotions.csv` file. \n",
    "El orden de los valores corresponde al orden de las columnas del archivo `emotions.csv`. La lista tiene 2548 valores que corresponden a los 2548 que su clasificador debe tomar como input. \n",
    "\n",
    "El endpoint debe retornar un json de la siguiente forma si la petición fue exitosa: \n",
    "\n",
    "```\n",
    "{\"output\":\"clasfOutput\"}\n",
    "```\n",
    "\n",
    "Donde \"clasfOutput\" corresponde a la predicción del clasificador (NEUTRAL, POSITIVE o NEGATIVE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to part 5 (endpoint url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
